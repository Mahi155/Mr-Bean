{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Train.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"Mrframe%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f4498a4a8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = plt.imread('Mrframe0.jpg')   # reading image using its name\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mrframe0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrframe1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mrframe2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrframe3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrframe4.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Image_ID  Class\n",
       "0  Mrframe0.jpg      0\n",
       "1  Mrframe1.jpg      0\n",
       "2  Mrframe2.jpg      0\n",
       "3  Mrframe3.jpg      0\n",
       "4  Mrframe4.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Mrmapping.csv')     # reading the csv file\n",
    "data.head()      # printing first five rows of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [ ]     # creating an empty array\n",
    "for img_name in data.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    X.append(img)  # storing each image in array X\n",
    "X = np.array(X)    # converting list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.Class\n",
    "dummy_y = np_utils.to_categorical(y)    # one hot encoding Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAIRAM_LUKKA\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\SAIRAM_LUKKA\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "image = []\n",
    "for i in range(0,X.shape[0]):\n",
    "    a = resize(X[i], preserve_range=True, output_shape=(224,224,3)).astype(int)      # reshaping to 224*224*3\n",
    "    image.append(a)\n",
    "X = np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X, mode='tf')      # preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))    # include_top=False to remove the top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125, 7, 7, 512), (54, 7, 7, 512))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = base_model.predict(X_train)\n",
    "X_valid = base_model.predict(X_valid)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(125, 7*7*512)      # converting to 1-D\n",
    "X_valid = X_valid.reshape(54, 7*7*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train/X_train.max()      # centering the data\n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i. Building the model\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 25,693,186\n",
      "Trainable params: 25,693,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii. Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.5585 - accuracy: 0.7120 - val_loss: 0.5864 - val_accuracy: 0.6481\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 0.1465 - accuracy: 0.9520 - val_loss: 0.3394 - val_accuracy: 0.8889\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0685 - accuracy: 0.9840 - val_loss: 0.2547 - val_accuracy: 0.9444\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.8704\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.8704\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.8704\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9444\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9444\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9444\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9444\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2572 - val_accuracy: 0.9444\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 9.5175e-04 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9444\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 8.9602e-04 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9444\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 8.5590e-04 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9444\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 8.3293e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9444\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 8.1293e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 7.9085e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 7.7056e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9444\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 7.5180e-04 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9444\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 7.3263e-04 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 7.1121e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9444\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 6.9568e-04 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 6.8182e-04 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 6.6678e-04 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 6.5291e-04 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 6.3911e-04 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 6.2630e-04 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 6.1292e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 5.9929e-04 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 5.8715e-04 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 5.7702e-04 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 5.6513e-04 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9444\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 5.5346e-04 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9444\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 5.4225e-04 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9444\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 5.3158e-04 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 5.2129e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9444\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 5.1201e-04 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9444\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 5.0174e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9444\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.9181e-04 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9444\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.8223e-04 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.7380e-04 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9444\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.6487e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 4.5712e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 4.4810e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.3932e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.3226e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.2430e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.1663e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 4.0913e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 4.0194e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 3.9486e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.8854e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.8119e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.7507e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9444\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 3.6899e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9444\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 3.6265e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 3.5617e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.5112e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.4506e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.3990e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.3354e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.2830e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 3.2370e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 3.1832e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.1329e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.0855e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 3.0360e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.9876e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.9462e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 2.9040e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.8588e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.8141e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.7731e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.7339e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.6964e-04 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.6555e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 2.6159e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 2.5808e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 2.5446e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.5079e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.4737e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.4361e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 2.4064e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.3731e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 2.3381e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 2.3108e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.2796e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.2481e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.2204e-04 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 2.1894e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 2.1623e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.1325e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 3s 25ms/step - loss: 2.1034e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 2.0806e-04 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 2.0497e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.0295e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 2s 19ms/step - loss: 1.9991e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17f01e8a550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Training the model\n",
    "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Screen time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "videoFile = \"Test.mp4\"\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename =\"Mrtest%d.jpg\" % count;count+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Mrtest1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for img_name in test.Image_ID:\n",
    "    img = plt.imread('' + img_name)\n",
    "    test_image.append(img)\n",
    "test_img = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = []\n",
    "for i in range(0,test_img.shape[0]):\n",
    "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
    "    test_image.append(a)\n",
    "test_image = np.array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the images\n",
    "test_image = preprocess_input(test_image, mode='tf')\n",
    "\n",
    "# extracting features from the images using pretrained model\n",
    "test_image = base_model.predict(test_image)\n",
    "\n",
    "# converting the images to 1-D form\n",
    "test_image = test_image.reshape(647, 7*7*512)\n",
    "\n",
    "# zero centered images\n",
    "test_image = test_image/test_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen time of Mr Bean is 411 seconds\n",
      "The screen time of others is 236 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"The screen time of Mr Bean is\", predictions[predictions==1].shape[0], \"seconds\")\n",
    "print(\"The screen time of others is\", predictions[predictions==0].shape[0], \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
